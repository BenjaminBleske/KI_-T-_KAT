# ğŸ± Cat-AI: Echtzeit-Erkennung & Datensammler
Dieses Projekt dient der automatisierten Ãœberwachung und Datensammlung fÃ¼r die Katzen Rocky und Scratchy mittels YOLOv8 auf einem Raspberry Pi 5. 

ğŸ“– ProjektÃ¼bersicht (3-Teilig)
## 1. test_detecion.py
Das HerzstÃ¼ck des Projekts ist das Skript test_detection.py. Es erfÃ¼llt drei Hauptaufgaben:

Live-Ãœberwachung: Verarbeitet einen RTSP-Kamerastream in Echtzeit.

KI-Klassifizierung: Erkennt Katzen und ordnet sie den trainierten Klassen zu.

Daten-Farming: Speichert automatisch neue Bilder inklusive fertiger YOLO-Labels ab, um den Datensatz fÃ¼r zukÃ¼nftige TrainingslÃ¤ufe (Fine-Tuning) zu erweitern.


## 2. Datenkuratierungs-Workflow
Um eine hohe DatenqualitÃ¤t fÃ¼r das Modell-Training sicherzustellen, wurde ein effizienter Bereinigungs-Workflow implementiert:

Sichten & Filtern: Nach dem Datensammeln mit test_detection.py werden die Ergebnisse im Ordner annotated_previews begutachtet. â€False Positivesâ€œ (Fehlerkennungen) oder qualitativ schlechte Bilder werden hier manuell gelÃ¶scht.

Synchronisieren: Das Skript clean_dataset.py vergleicht anschlieÃŸend die Inhalte von annotated_previews mit dem Ordner raw_training_data.

Bereinigen: Alle Bilder und Labels in raw_training_data, die zuvor in den Previews gelÃ¶scht wurden, werden vom Skript automatisch entfernt.

## 3. Yolo-Training
DarÃ¼ber hinaus ist eine Ordnerstruktur mit dem Namen *Training* implementiert. Die kuratierten Fotos aus raw_training_data mÃ¼ssen in Training/yolotraining_folder gemovet werden. AnschlieÃŸend muss im Verzeichnis das perpare_data.py Skript ausgefÃ¼hrt werden. 
Dann kann man das Training mit den untenstehenden Befehlen starten.
 
    conda create --name yolo8-env python=3.12 -y
    conda activate yolo8-env
    pip install ultralytics

    yolo train data=data.yaml model=yolov8n.pt epochs=90 imgsz=640 device=mps batch=16 workers=8

    oder ein anderes yolo Modell
    conda create --name yolo11-env python=3.12 -y
    conda activate yolo11-env
    pip install ultralytics
    yolo train data=data.yaml model=yolo11s.pt epochs=90 imgsz=640 device=mps batch=16 workers=8

# ğŸš€ Installation & Start (Raspberry Pi 5) test_detection.py

cd ki_skript
tmux new -s yolo
python -m venv yolo-env
source yolo-env/bin/activate
pip install ultralytics opencv-python
python test_detection.py

zurÃ¼ckholen?: 
tmux attach -t yolo
tmux kill-session -t yolo

# ğŸš€ Installation & Start (Mac) test_detection.py
conda create --name yolo8-env python=3.12 -y
conda activate yolo8-env
pip install ultralytics
caffeinate -i python test_detection.py

# ğŸ›  Funktionsweise des Skripts test_detection.py
Das Skript arbeitet in einem hybriden Modus und passt sich seiner Umgebung an:

Headless-Modus (SSH): Erkennt automatisch, wenn kein Monitor angeschlossen ist (z. B. bei einer SSH-Verbindung auf dem Pi) und deaktiviert die grafische Anzeige, um CPU-Ressourcen zu sparen.

Heartbeat-Log: Gibt im Terminal regelmÃ¤ÃŸig Statusmeldungen aus ("Scan aktiv..."), damit der Betrieb auch ohne Videobild Ã¼berwacht werden kann.

Intelligentes Speichern (Debouncing): Um Speicherplatz zu sparen, wird nach einer erfolgreichen Erkennung eine Sperrfrist (standardmÃ¤ÃŸig 5 Sekunden) aktiviert, bevor fÃ¼r dieselbe Katze ein neues Bild gespeichert wird.

# ğŸ“‚ Ordnerstruktur die durch test_detection.py erstellt wird
Nach dem Start des Skripts werden automatisch zwei Verzeichnisse verwaltet:

Ordner | Inhalt | Zweck
--|--|--|
raw_training_data/ | Saubere .jpg + .txt | Die Rohdaten fÃ¼r das nÃ¤chste KI-Training.
annotated_previews/ | Bilder mit grÃ¼nen Boxen | Zur schnellen menschlichen Kontrolle: Hat die KI recht?


## Prozess test_detection.py beenden
tmux kill-session -t yolo

# ğŸ”„ Der Workflow (Kurzzusammenfassung)
Um das Modell immer besser zu machen, folgt das Projekt diesem Kreislauf:

Sammeln: Der Pi lÃ¤sst das Skript test_detection.py laufen und fÃ¼llt die Ordner.

Sichten: Du lÃ¶schst in annotated_previews alle Bilder, die Fehler enthalten (falsche Katze oder Fehlalarm).

Bereinigen: Das Skript clean_dataset.py synchronisiert raw_training_data (lÃ¶scht die dazugehÃ¶rigen Labels der entfernten Bilder).

Trainieren: Die sauberen Daten werden fÃ¼r ein neues Training genutzt.

Tipp: Da typischerweise Ã¼ber ssh in den PI connected wird, bietet es sich an die beiden Dateien annotaded_previews und raw_training_data herunterzuladen und anschlieÃŸend auf dem PI zu lÃ¶schen. Das hat auch den Vorteil, dass der Raspi nicht so schnell vollÃ¤uft.

# Konfiguration test_detection.py
Wichtige Parameter am Anfang der test_detection.py:

CONF_THRESHOLD: Ab welcher Sicherheit (z.B. 0.40) soll eine Katze gezÃ¤hlt werden?

MIN_TIME_BETWEEN_SAVES: Zeitabstand zwischen Speicherungen derselben Katze.

SOURCE: Die RTSP-Adresse deiner Kamera.

# Weitere Ordner

Ordner | Zweck |
--|--|
Training/model_trained_on/raw_trainig_data | Rohdaten (Bilder inkl. Labels) fÃ¼r best.pt |
Training/yolotraining_folder | Yolo-Training-Folder: FÃ¼r ein Training muss der Ordner raw_training_data gefÃ¼llt werden, der sich ebenfalls yolotraining_folder befinden muss|

# git push
git status
git add .
git commit -m "Readme-Update"
git push
